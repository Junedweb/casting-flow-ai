
[build]
  publish = "dist"
  command = "npm run build"

[build.environment]
  NODE_VERSION = "18"

# Crawler-friendly redirects - handle known crawler paths first
[[redirects]]
  from = "/robots.txt"
  to = "/robots.txt"
  status = 200
  
[[redirects]]
  from = "/sitemap.xml"
  to = "/sitemap.xml"
  status = 200

# Enhanced crawler user agent detection for preview and production
[[redirects]]
  from = "/*"
  to = "/index.html"
  status = 200
  conditions = {User-Agent = "Googlebot,Bingbot,Slurp,DuckDuckBot,Baiduspider,YandexBot,facebookexternalhit,Twitterbot,LinkedInBot,WhatsApp,TelegramBot,ChatGPT-User,GPTBot,Google-Extended,CCBot,anthropic-ai,Claude-Web,Mozilla/5.0 AppleWebKit (KHTML like Gecko) Chrome Safari ChatGPT"}
  force = false

# Additional ChatGPT specific patterns
[[redirects]]
  from = "/*"
  to = "/index.html"
  status = 200
  conditions = {User-Agent = "*ChatGPT*,*GPT*,*OpenAI*,*anthropic*,*claude*"}
  force = false

# Main SPA redirect for regular users - must be last
[[redirects]]
  from = "/*"
  to = "/index.html"
  status = 200

# Enhanced security and performance headers
[[headers]]
  for = "/*"
  [headers.values]
    X-Frame-Options = "SAMEORIGIN"
    X-XSS-Protection = "1; mode=block"
    X-Content-Type-Options = "nosniff"
    Referrer-Policy = "strict-origin-when-cross-origin"
    Permissions-Policy = "camera=(), microphone=(), geolocation=()"
    X-Robots-Tag = "index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"
    Cache-Control = "public, max-age=1800"
    Access-Control-Allow-Origin = "*"
    Access-Control-Allow-Methods = "GET, POST, OPTIONS"
    Access-Control-Allow-Headers = "Content-Type, User-Agent"

# ChatGPT and AI crawler specific headers
[[headers]]
  for = "/"
  [headers.values]
    X-Robots-Tag = "index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"
    Cache-Control = "public, max-age=300"
    Vary = "User-Agent"
    Content-Type = "text/html; charset=utf-8"

# Robots.txt headers
[[headers]]
  for = "/robots.txt"
  [headers.values]
    Content-Type = "text/plain; charset=utf-8"
    Cache-Control = "public, max-age=86400"
    X-Robots-Tag = "noindex"

# Sitemap headers
[[headers]]
  for = "/sitemap.xml"
  [headers.values]
    Content-Type = "application/xml; charset=utf-8"
    Cache-Control = "public, max-age=86400"
    X-Robots-Tag = "noindex"

# Static asset caching
[[headers]]
  for = "*.js"
  [headers.values]
    Cache-Control = "public, max-age=31536000, immutable"

[[headers]]
  for = "*.css"
  [headers.values]
    Cache-Control = "public, max-age=31536000, immutable"

[[headers]]
  for = "*.woff2"
  [headers.values]
    Cache-Control = "public, max-age=31536000, immutable"

[[headers]]
  for = "*.jpg"
  [headers.values]
    Cache-Control = "public, max-age=31536000, immutable"

[[headers]]
  for = "*.png"
  [headers.values]
    Cache-Control = "public, max-age=31536000, immutable"

[[headers]]
  for = "*.webp"
  [headers.values]
    Cache-Control = "public, max-age=31536000, immutable"
